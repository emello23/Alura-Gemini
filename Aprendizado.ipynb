{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emello23/Alura-Gemini/blob/main/Aprendizado.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Montar o Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "5OWaN1U79C-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalar/Atualizar as bibliotecas necessárias\n",
        "!pip install --upgrade genai PyMuPDF\n",
        "\n",
        "!pi show genai"
      ],
      "metadata": {
        "id": "lGCELBEr-InA",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from google import genai\n",
        "from genai import types as genai_types  # Importação ativa\n",
        "import fitz  # Importa a biblioteca PyMuPDF"
      ],
      "metadata": {
        "id": "Du_leth3cD3v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configurar a chave da API\n",
        "os.environ['GOOGLE_API_KEY'] = userdata.get('GOOGLE_API_KEY')\n",
        "client = genai.Client()"
      ],
      "metadata": {
        "id": "vqkXAdE8cJxT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir o modelo a ser usado\n",
        "modelo = \"gemini-2.0-flash\"\n"
      ],
      "metadata": {
        "id": "gL-FVrZVcX38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- PARTE ONDE VOCÊ CARREGA O PDF ---\n",
        "# Atualize o caminho do PDF para apontar para o seu arquivo no Google Drive\n",
        "# Alternativa: Coloque o arquivo na sua pasta raiz do My Drive\n",
        "#              e renomei-o para aprendizado.pdf mantendo este mesmo caminho.\n",
        "caminho_do_pdf = \"/content/drive/My Drive/aprendizado.pdf\" # <-- ATUALIZE ESTA LINHA COM O CAMINHO CORRETO'"
      ],
      "metadata": {
        "id": "4WNFIXhQl0Ff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extrair_texto_de_pdf(caminho_do_arquivo):\n",
        "    \"\"\"Extrai texto de um arquivo PDF.\"\"\"ivaivaa\n",
        "    texto_completo = \"\"\n",
        "    try:\n",
        "        documento = fitz.open(caminho_do_arquivo)\n",
        "        for pagina_num in range(documento.page_count):\n",
        "            pagina = documento.load_page(pagina_num)\n",
        "            texto_completo += pagina.get_text()\n",
        "        documento.close()\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao extrair texto do PDF: {e}\")\n",
        "        texto_completo = None # Retorna None em caso de erro\n",
        "    return texto_completo\n",
        "\n"
      ],
      "metadata": {
        "id": "SVIA1oYHcj1g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texto_do_pdf = extrair_texto_de_pdf(caminho_do_pdf)\n",
        "\n"
      ],
      "metadata": {
        "id": "aRPFYuJscmC2",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if texto_do_pdf: # Verifica se a extração do texto foi bem-sucedida\n",
        "    print(\"Texto extraído do PDF (primeiros 500 caracteres):\")\n",
        "    print(texto_do_pdf[:500] + \"...\") # Mostra apenas uma parte do texto para não sobrecarregar\n",
        "\n",
        "    # --- USANDO GEMINI PARA AJUDAR COM RESUMO E TÓPICOS ---\n",
        "    # Gerar um resumo inicial\n",
        "    try:\n",
        "        response_resumo = client.models.generate_content(\n",
        "            model=modelo,\n",
        "            contents=f\"Por favor, gere um resumo conciso do seguinte texto:\\n\\n{texto_do_pdf}\"\n",
        "        )\n",
        "        resumo = response_resumo.text\n",
        "        print(\"\\nResumo gerado pelo Gemini:\")\n",
        "        print(resumo)\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao gerar resumo: {e}\")\n",
        "\n",
        "\n",
        "    # Tentar identificar tópicos principais\n",
        "    try:\n",
        "        response_topicos = client.models.generate_content(\n",
        "            model=modelo,\n",
        "            contents=f\"Por favor, liste os principais tópicos e sub-tópicos (numerados se possível) encontrados no seguinte texto:\\n\\n{texto_do_pdf}\"\n",
        "        )\n",
        "        topicos_identificados = response_topicos.text\n",
        "        print(\"\\nTópicos identificados pelo Gemini:\")\n",
        "        print(topicos_identificados)\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao identificar tópicos: {e}\")\n",
        "\n",
        "    # --- PARTE DO CHATBOT ---\n",
        "    print(\"\\nOk! Vamos aprender sobre o conteúdo do documento.\")\n",
        "    print(\"Eu farei perguntas sobre o conteúdo do documento. Tente respondê-las!\")\n",
        "    print(\"Digite 'fim' para encerrar o chat.\")\n",
        "\n",
        "    # Abordagem para gerar perguntas\n",
        "    try:\n",
        "        response_perguntas = client.models.generate_content(\n",
        "            model=modelo,\n",
        "            contents=f\"Com base no seguinte texto, gere 5 perguntas sobre o seu conteúdo para que um usuário possa respondê-las. Liste as perguntas numeradas.\\n\\n{texto_do_pdf}\"\n",
        "        )\n",
        "\n",
        "        perguntas_geradas = response_perguntas.text.split('\\n') # Divide as perguntas em uma lista\n",
        "        # Filtra linhas vazias e numerações que não são perguntas válidas\n",
        "        perguntas_validas = [p.strip() for p in perguntas_geradas if p.strip() and any(char.isdigit() for char in p.strip().split('.')[0])]\n",
        "\n",
        "\n",
        "        if not perguntas_validas:\n",
        "            print(\"Não foi possível gerar perguntas a partir do PDF.\")\n",
        "        else:\n",
        "            indice_pergunta_atual = 0\n",
        "\n",
        "            while indice_pergunta_atual < len(perguntas_validas):\n",
        "                pergunta_atual = perguntas_validas[indice_pergunta_atual]\n",
        "                print(f\"\\nPergunta {indice_pergunta_atual + 1}: {pergunta_atual}\")\n",
        "\n",
        "                resposta_usuario = input(\"Sua resposta: \")\n",
        "\n",
        "                if resposta_usuario.lower() == \"fim\":\n",
        "                    print(\"Chat encerrado. Até a próxima!\")\n",
        "                    break\n",
        "\n",
        "                # Usar o Gemini para avaliar a resposta do usuário\n",
        "                try:\n",
        "                    chat_avaliacao_config = genai_types.GenerateContentConfig(\n",
        "                      system_instruction = f\"Você é um avaliador de respostas baseado no seguinte texto. A pergunta foi: '{pergunta_atual}'. Avalie a resposta do usuário ('{resposta_usuario}') com base no texto original e diga se ela está correta, incorreta ou parcialmente correta, explicando brevemente por que. O texto original é:\\n\\n{texto_do_pdf}\"\n",
        "                    )\n",
        "                    chat_avaliacao = client.chats.create(model=modelo, config=chat_avaliacao_config)\n",
        "                    response_avaliacao = chat_avaliacao.send_message(f\"Pergunta: {pergunta_atual}\\nResposta do usuário: {resposta_usuario}\")\n",
        "\n",
        "                    print(\"Avaliação do Gemini: \", response_avaliacao.text)\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"Erro ao avaliar a resposta: {e}\")\n",
        "\n",
        "                indice_pergunta_atual += 1 # Passa para a próxima pergunta\n",
        "\n",
        "            if indice_pergunta_atual == len(perguntas_validas):\n",
        "              print(\"\\nVocê respondeu a todas as perguntas. Chat encerrado. Até a próxima!\")\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao gerar perguntas ou executar o loop do chatbot: {e}\")\n",
        "\n",
        "else:\n",
        "    print(\"Não foi possível prosseguir porque a extração do texto do PDF falhou.\")\n"
      ],
      "metadata": {
        "id": "5NqUUfCKRQ8H"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}